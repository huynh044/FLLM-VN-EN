{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11cab4da",
   "metadata": {},
   "source": [
    "# Vietnamese-English Translation với PyTorch 2.5.1\n",
    "\n",
    "**Hướng dẫn đơn giản để fine-tune model dịch Việt-Anh**\n",
    "\n",
    "## 🎯 Mục tiêu\n",
    "- Fine-tune model mT5 cho dịch thuật Việt-Anh\n",
    "- Sử dụng LoRA để training hiệu quả\n",
    "- Tương thích hoàn toàn với PyTorch 2.5.1+cu121\n",
    "\n",
    "## 📋 Các bước thực hiện\n",
    "1. ✅ Cài đặt thư viện cần thiết\n",
    "2. ✅ Tạo dataset Vietnamese-English\n",
    "3. ✅ Load và chuẩn bị model mT5\n",
    "4. ✅ Setup LoRA cho efficient training\n",
    "5. ✅ Training với parameters tối ưu\n",
    "6. ✅ Test và đánh giá kết quả\n",
    "\n",
    "## 🔧 Yêu cầu hệ thống\n",
    "- Python 3.8+\n",
    "- PyTorch 2.5.1+cu121\n",
    "- GPU với CUDA 12.1 (hoặc CPU)\n",
    "- RAM: 8GB+ (16GB khuyến nghị)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8af4ff",
   "metadata": {},
   "source": [
    "## Bước 1: Cài đặt thư viện\n",
    "\n",
    "**Quan trọng:** Sử dụng PyTorch 2.5.1+cu121 để tương thích tốt nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7977393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt PyTorch 2.5.1 với CUDA 12.1\n",
    "!pip install torch==2.5.1+cu121 torchvision==0.20.1+cu121 torchaudio==2.5.1+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Cài đặt thư viện machine learning\n",
    "!pip install transformers>=4.44.0 datasets>=2.20.0 accelerate>=0.33.0 peft>=0.12.0 safetensors>=0.4.0\n",
    "\n",
    "# Cài đặt thư viện đánh giá\n",
    "!pip install evaluate rouge-score\n",
    "\n",
    "# Cài đặt thư viện phụ trợ\n",
    "!pip install pandas numpy matplotlib tqdm\n",
    "\n",
    "print(\"✅ Đã cài đặt tất cả thư viện cần thiết!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d51d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import thư viện cần thiết\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "\n",
    "# PEFT cho LoRA\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Kiểm tra GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🔧 Sử dụng device: {device}\")\n",
    "print(f\"🐍 Python version: {torch.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"🎮 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(f\"🔥 CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"⚠️ Chạy trên CPU - sẽ chậm hơn\")\n",
    "\n",
    "# Đặt random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "print(\"✅ Setup hoàn tất!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e3d581",
   "metadata": {},
   "source": [
    "## Bước 2: Tạo Dataset Vietnamese-English\n",
    "\n",
    "Tạo dataset đơn giản để demo. Trong thực tế, bạn sẽ sử dụng dataset lớn hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1838dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo dataset Vietnamese-English đơn giản, dataaset sẽ trông như thế này:\n",
    "data = [\n",
    "    {\"vn\": \"Xin chào\", \"en\": \"Hello\"},\n",
    "    {\"vn\": \"Tạm biệt\", \"en\": \"Goodbye\"},\n",
    "    {\"vn\": \"Cảm ơn bạn\", \"en\": \"Thank you\"},\n",
    "    {\"vn\": \"Xin lỗi\", \"en\": \"Sorry\"},\n",
    "    {\"vn\": \"Bạn khỏe không?\", \"en\": \"How are you?\"},\n",
    "    {\"vn\": \"Tôi tên là Nam\", \"en\": \"My name is Nam\"},\n",
    "    {\"vn\": \"Hôm nay thời tiết đẹp\", \"en\": \"The weather is nice today\"},\n",
    "    {\"vn\": \"Tôi thích ăn phở\", \"en\": \"I like to eat pho\"},\n",
    "    {\"vn\": \"Chúc bạn ngủ ngon\", \"en\": \"Good night\"},\n",
    "    {\"vn\": \"Hẹn gặp lại\", \"en\": \"See you later\"},\n",
    "    {\"vn\": \"Tôi đang học tiếng Anh\", \"en\": \"I am learning English\"},\n",
    "    {\"vn\": \"Bạn có thể giúp tôi không?\", \"en\": \"Can you help me?\"},\n",
    "    {\"vn\": \"Tôi yêu Việt Nam\", \"en\": \"I love Vietnam\"},\n",
    "    {\"vn\": \"Hà Nội là thủ đô\", \"en\": \"Hanoi is the capital\"},\n",
    "    {\"vn\": \"Món này rất ngon\", \"en\": \"This dish is delicious\"},\n",
    "    {\"vn\": \"Tôi muốn đi du lịch\", \"en\": \"I want to travel\"},\n",
    "    {\"vn\": \"Gia đình tôi có 4 người\", \"en\": \"My family has 4 people\"},\n",
    "    {\"vn\": \"Tôi làm việc ở văn phòng\", \"en\": \"I work at the office\"},\n",
    "    {\"vn\": \"Chúng ta đi ăn nhé\", \"en\": \"Let's go eat\"},\n",
    "    {\"vn\": \"Tôi thích xem phim\", \"en\": \"I like watching movies\"}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"📊 Tạo dataset với {len(df)} cặp câu\")\n",
    "print(\"\\n🔍 Một số ví dụ:\")\n",
    "for i in range(3):\n",
    "    print(f\"🇻🇳 {df.iloc[i]['vn']} → 🇺🇸 {df.iloc[i]['en']}\")\n",
    "    \n",
    "print(f\"\\n📈 Thống kê:\")\n",
    "print(f\"Trung bình từ tiếng Việt: {df['vn'].str.split().str.len().mean():.1f}\")\n",
    "print(f\"Trung bình từ tiếng Anh: {df['en'].str.split().str.len().mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92d29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn bị data cho T5 format\n",
    "def create_t5_format(vn_text, en_text):\n",
    "    \"\"\"Tạo format cho T5: 'translate Vietnamese to English: [VN]' -> '[EN]'\"\"\"\n",
    "    input_text = f\"translate Vietnamese to English: {vn_text}\"\n",
    "    target_text = en_text\n",
    "    return input_text, target_text\n",
    "\n",
    "# Tạo dataset với T5 format\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    inp, tgt = create_t5_format(row['vn'], row['en'])\n",
    "    inputs.append(inp)\n",
    "    targets.append(tgt)\n",
    "\n",
    "print(\"🔄 Ví dụ T5 format:\")\n",
    "print(f\"Input: {inputs[0]}\")\n",
    "print(f\"Target: {targets[0]}\")\n",
    "\n",
    "# Tạo Hugging Face Dataset\n",
    "dataset = Dataset.from_dict({\n",
    "    'input_text': inputs,\n",
    "    'target_text': targets\n",
    "})\n",
    "\n",
    "# Chia train/validation (80/20)\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset = dataset.select(range(train_size))\n",
    "val_dataset = dataset.select(range(train_size, len(dataset)))\n",
    "\n",
    "print(f\"\\n📊 Chia dataset:\")\n",
    "print(f\"Training: {len(train_dataset)} samples\")\n",
    "print(f\"Validation: {len(val_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4ae0b",
   "metadata": {},
   "source": [
    "## Bước 3: Load Model và Tokenizer\n",
    "\n",
    "Sử dụng mT5-small - model nhỏ nhưng hiệu quả cho demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2456ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model và tokenizer\n",
    "MODEL_NAME = \"google/mt5-small\"\n",
    "print(f\"📥 Loading model: {MODEL_NAME}\")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(f\"📚 Tokenizer vocabulary: {len(tokenizer):,} tokens\")\n",
    "\n",
    "# Test tokenization\n",
    "test_text = \"translate Vietnamese to English: Xin chào\"\n",
    "tokens = tokenizer.tokenize(test_text)\n",
    "print(f\"\\n🧪 Test tokenization:\")\n",
    "print(f\"Text: {test_text}\")\n",
    "print(f\"Tokens: {tokens[:10]}...\")  # Chỉ hiển thị 10 tokens đầu\n",
    "print(f\"Token IDs: {tokenizer.encode(test_text)[:10]}...\")\n",
    "\n",
    "print(\"✅ Tokenizer sẵn sàng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data in T5 format: \"translate Vietnamese to English: [VN_TEXT]\" -> \"[EN_TEXT]\"\n",
    "def create_t5_format(vietnamese_text, english_text):\n",
    "    \"\"\"Create T5 input-output format.\"\"\"\n",
    "    input_text = f\"translate Vietnamese to English: {vietnamese_text}\"\n",
    "    target_text = english_text\n",
    "    return input_text, target_text\n",
    "\n",
    "# Create T5 formatted data\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    input_text, target_text = create_t5_format(\n",
    "        row['vietnamese_clean'], \n",
    "        row['english_clean']\n",
    "    )\n",
    "    inputs.append(input_text)\n",
    "    targets.append(target_text)\n",
    "\n",
    "# Create Hugging Face Dataset\n",
    "dataset_dict = {\n",
    "    'input_text': inputs,\n",
    "    'target_text': targets,\n",
    "    'vietnamese': df['vietnamese_clean'].tolist(),\n",
    "    'english': df['english_clean'].tolist()\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(dataset_dict)\n",
    "\n",
    "# Split into train/validation sets (80/20 split)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "train_dataset = dataset.select(range(train_size))\n",
    "val_dataset = dataset.select(range(train_size, len(dataset)))\n",
    "\n",
    "dataset_splits = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})\n",
    "\n",
    "print(f\"📊 Dataset splits:\")\n",
    "print(f\"  Training: {len(train_dataset)} examples\")\n",
    "print(f\"  Validation: {len(val_dataset)} examples\")\n",
    "\n",
    "# Show example of formatted data\n",
    "print(f\"\\n🔍 Example formatted data:\")\n",
    "example = train_dataset[0]\n",
    "print(f\"Input: {example['input_text']}\")\n",
    "print(f\"Target: {example['target_text']}\")\n",
    "\n",
    "# Tokenize dataset\n",
    "max_length = 128\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenize input và target texts\"\"\"\n",
    "    # Tokenize inputs\n",
    "    inputs = tokenizer(\n",
    "        examples['input_text'],\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding=False  # Padding động trong training\n",
    "    )\n",
    "    \n",
    "    # Tokenize targets\n",
    "    targets = tokenizer(\n",
    "        examples['target_text'],\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding=False\n",
    "    )\n",
    "    \n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# Tokenize cả train và validation\n",
    "print(\"🔄 Tokenizing dataset...\")\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Xóa columns không cần thiết\n",
    "train_dataset = train_dataset.remove_columns(['input_text', 'target_text'])\n",
    "val_dataset = val_dataset.remove_columns(['input_text', 'target_text'])\n",
    "\n",
    "print(f\"✅ Tokenization hoàn tất!\")\n",
    "print(f\"📊 Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"📊 Val dataset: {len(val_dataset)} samples\")\n",
    "\n",
    "# Kiểm tra 1 sample\n",
    "sample = train_dataset[0]\n",
    "print(f\"\\n🔍 Sample tokenized:\")\n",
    "print(f\"Input length: {len(sample['input_ids'])}\")\n",
    "print(f\"Labels length: {len(sample['labels'])}\")\n",
    "print(f\"Input tokens: {tokenizer.convert_ids_to_tokens(sample['input_ids'][:5])}\")\n",
    "print(f\"Label tokens: {tokenizer.convert_ids_to_tokens(sample['labels'][:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3dbb41",
   "metadata": {},
   "source": [
    "## Bước 4: Load Model và Setup LoRA\n",
    "\n",
    "Tương thích với PyTorch 2.5.1+cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bc41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model với PyTorch 2.5.1 compatibility\n",
    "print(f\"📥 Loading model: {MODEL_NAME}\")\n",
    "\n",
    "# Load model với float32 cho stability\n",
    "try:\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        torch_dtype=torch.float32,  # Sử dụng float32 cho PyTorch 2.5.1\n",
    "        use_safetensors=True\n",
    "    )\n",
    "    print(\"✅ Model loaded với safetensors\")\n",
    "except:\n",
    "    print(\"⚠️ Safetensors failed, trying fallback...\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        torch_dtype=torch.float32\n",
    "    )\n",
    "    print(\"✅ Model loaded với fallback\")\n",
    "\n",
    "print(f\"📊 Model có {model.num_parameters():,} parameters\")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "print(f\"🔧 Model moved to {device}\")\n",
    "\n",
    "# Setup LoRA cho efficient training\n",
    "print(\"\\n🔧 Setting up LoRA...\")\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    inference_mode=False,\n",
    "    r=8,                    # LoRA rank (nhỏ hơn để đơn giản)\n",
    "    lora_alpha=16,          # LoRA alpha\n",
    "    lora_dropout=0.1,       # LoRA dropout\n",
    "    target_modules=[\"q\", \"v\"]  # Target attention modules\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100,\n",
    "    pad_to_multiple_of=8 if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "print(\"✅ LoRA setup hoàn tất!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc815fd7",
   "metadata": {},
   "source": [
    "## Bước 5: Setup Training Arguments\n",
    "\n",
    "Cấu hình tối ưu cho PyTorch 2.5.1 và dataset nhỏ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73557582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments đơn giản và hiệu quả\n",
    "output_dir = \"./results/mt5-vi-en-simple\"\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    \n",
    "    # Basic training settings\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    \n",
    "    # Learning rate\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=50,\n",
    "    \n",
    "    # Evaluation\n",
    "    eval_steps=25,\n",
    "    save_steps=25,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    \n",
    "    # Generation settings\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=max_length,\n",
    "    generation_num_beams=4,\n",
    "    \n",
    "    # Tối ưu cho PyTorch 2.5.1\n",
    "    fp16=False,  # Tắt fp16 cho stability\n",
    "    dataloader_num_workers=0,\n",
    "    remove_unused_columns=False,\n",
    "    \n",
    "    # Save settings\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    \n",
    "    # Reporting\n",
    "    report_to=None,  # Tắt wandb\n",
    ")\n",
    "\n",
    "print(\"⚙️ Training arguments:\")\n",
    "print(f\"  📁 Output: {output_dir}\")\n",
    "print(f\"  🔢 Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"  📏 Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  📊 Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"  🎯 Eval steps: {training_args.eval_steps}\")\n",
    "print(f\"  🔥 FP16: {training_args.fp16}\")\n",
    "print(\"✅ Training arguments sẵn sàng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d5746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation metrics\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    \"\"\"Compute BLEU score\"\"\"\n",
    "    predictions, labels = eval_preds\n",
    "    \n",
    "    # Decode predictions\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Decode labels (replace -100 with pad token)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Clean text\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [label.strip() for label in decoded_labels]\n",
    "    \n",
    "    # Compute BLEU\n",
    "    result = bleu_metric.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=[[label] for label in decoded_labels]\n",
    "    )\n",
    "    \n",
    "    # Return result\n",
    "    return {\n",
    "        \"bleu\": result[\"bleu\"],\n",
    "        \"prediction_length\": np.mean([len(pred.split()) for pred in decoded_preds])\n",
    "    }\n",
    "\n",
    "print(\"📊 Setting up evaluation metrics...\")\n",
    "print(\"✅ Metrics sẵn sàng - sử dụng BLEU score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae92939",
   "metadata": {},
   "source": [
    "## Bước 6: Training Model\n",
    "\n",
    "Bắt đầu fine-tuning với LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa0e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "print(\"🚀 Tạo Trainer...\")\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(f\"📊 Training dataset: {len(train_dataset)} samples\")\n",
    "print(f\"📊 Validation dataset: {len(val_dataset)} samples\")\n",
    "\n",
    "# Test model trước khi training\n",
    "print(\"\\n🧪 Test model trước training:\")\n",
    "test_input = \"translate Vietnamese to English: Xin chào\"\n",
    "inputs = tokenizer.encode(test_input, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(inputs, max_length=50, num_beams=2, do_sample=False)\n",
    "    before_translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Trước training: {before_translation}\")\n",
    "\n",
    "# Bắt đầu training\n",
    "print(\"\\n🏋️ Bắt đầu training...\")\n",
    "print(\"💡 Tip: Training sẽ mất vài phút, hãy kiên nhẫn!\")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n✅ Training hoàn tất!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c901b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu model\n",
    "print(\"💾 Lưu model...\")\n",
    "model.save_pretrained(f\"{output_dir}/final_model\")\n",
    "tokenizer.save_pretrained(f\"{output_dir}/final_model\")\n",
    "print(f\"✅ Model đã lưu tại: {output_dir}/final_model\")\n",
    "\n",
    "# Đánh giá cuối cùng\n",
    "print(\"\\n📊 Đánh giá cuối cùng...\")\n",
    "final_results = trainer.evaluate()\n",
    "print(f\"📈 Final BLEU Score: {final_results.get('eval_bleu', 0):.4f}\")\n",
    "print(f\"📉 Final Loss: {final_results.get('eval_loss', 0):.4f}\")\n",
    "\n",
    "# Test model sau training\n",
    "print(\"\\n🧪 Test model sau training:\")\n",
    "test_input = \"translate Vietnamese to English: Xin chào\"\n",
    "inputs = tokenizer.encode(test_input, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(inputs, max_length=50, num_beams=4, do_sample=False)\n",
    "    after_translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Sau training: {after_translation}\")\n",
    "\n",
    "# Vẽ training history nếu có\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Lấy training logs\n",
    "    logs = trainer.state.log_history\n",
    "    \n",
    "    if logs:\n",
    "        # Tách train và eval logs\n",
    "        train_logs = [log for log in logs if 'train_loss' in log]\n",
    "        eval_logs = [log for log in logs if 'eval_loss' in log]\n",
    "        \n",
    "        if train_logs and eval_logs:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "            \n",
    "            # Training loss\n",
    "            steps = [log['step'] for log in train_logs]\n",
    "            losses = [log['train_loss'] for log in train_logs]\n",
    "            ax1.plot(steps, losses, 'b-', label='Training Loss')\n",
    "            ax1.set_title('Training Loss')\n",
    "            ax1.set_xlabel('Steps')\n",
    "            ax1.set_ylabel('Loss')\n",
    "            ax1.legend()\n",
    "            \n",
    "            # Eval loss\n",
    "            eval_steps = [log['step'] for log in eval_logs]\n",
    "            eval_losses = [log['eval_loss'] for log in eval_logs]\n",
    "            ax2.plot(eval_steps, eval_losses, 'r-', label='Validation Loss')\n",
    "            ax2.set_title('Validation Loss')\n",
    "            ax2.set_xlabel('Steps')\n",
    "            ax2.set_ylabel('Loss')\n",
    "            ax2.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"📊 Training charts được tạo!\")\n",
    "        else:\n",
    "            print(\"⚠️ Không có đủ dữ liệu để vẽ charts\")\n",
    "    else:\n",
    "        print(\"⚠️ Không có training logs\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Không thể vẽ charts: {e}\")\n",
    "\n",
    "print(\"\\n🎉 Training hoàn tất!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183c6835",
   "metadata": {},
   "source": [
    "## Bước 7: Test Translation\n",
    "\n",
    "Kiểm tra chất lượng dịch thuật với các câu mới"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa0370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the fine-tuned model\n",
    "print(\"📊 Evaluating fine-tuned model...\")\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"\\n🎯 Evaluation Results:\")\n",
    "for key, value in eval_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Tạo function dịch thuật đơn giản\n",
    "def translate_text(vietnamese_text, max_length=64, num_beams=4):\n",
    "    \"\"\"Dịch từ tiếng Việt sang tiếng Anh\"\"\"\n",
    "    input_text = f\"translate Vietnamese to English: {vietnamese_text}\"\n",
    "    \n",
    "    # Encode input\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=max_length, truncation=True).to(device)\n",
    "    \n",
    "    # Generate translation\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=max_length,\n",
    "            num_beams=num_beams,\n",
    "            early_stopping=True,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode output\n",
    "    translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translation\n",
    "\n",
    "# Test với validation set\n",
    "print(\"🧪 Test trên validation set:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(len(val_dataset)):\n",
    "    # Reconstruct original text từ tokenized data\n",
    "    input_ids = val_dataset[i]['input_ids']\n",
    "    label_ids = val_dataset[i]['labels']\n",
    "    \n",
    "    # Decode để lấy text gốc\n",
    "    input_text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "    reference = tokenizer.decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # Extract Vietnamese text từ input\n",
    "    vietnamese_text = input_text.replace(\"translate Vietnamese to English: \", \"\")\n",
    "    \n",
    "    # Dịch\n",
    "    prediction = translate_text(vietnamese_text)\n",
    "    \n",
    "    # So sánh (đơn giản)\n",
    "    if reference.lower().strip() in prediction.lower().strip():\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    \n",
    "    print(f\"🇻🇳 Tiếng Việt: {vietnamese_text}\")\n",
    "    print(f\"🎯 Đáp án:     {reference}\")\n",
    "    print(f\"🤖 Dự đoán:    {prediction}\")\n",
    "    print(f\"{'✅ Đúng' if reference.lower().strip() in prediction.lower().strip() else '❌ Sai'}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "accuracy = correct / total * 100\n",
    "print(f\"\\n📊 Kết quả:\")\n",
    "print(f\"Độ chính xác: {accuracy:.1f}% ({correct}/{total})\")\n",
    "\n",
    "if accuracy > 70:\n",
    "    print(\"🎉 Tuyệt vời! Model hoạt động tốt!\")\n",
    "elif accuracy > 50:\n",
    "    print(\"👍 Khá tốt! Có thể cải thiện thêm.\")\n",
    "else:\n",
    "    print(\"⚠️ Cần training thêm hoặc tăng data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed93941",
   "metadata": {},
   "source": [
    "## Bước 8: Test với câu mới\n",
    "\n",
    "Thử nghiệm với các câu tiếng Việt chưa có trong training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a translation function\n",
    "def translate_vietnamese(text, max_length=128, num_beams=4):\n",
    "    \"\"\"Translate Vietnamese text to English using our fine-tuned model.\"\"\"\n",
    "    input_text = f\"translate Vietnamese to English: {text}\"\n",
    "    inputs = tokenizer.encode(\n",
    "        input_text, \n",
    "        return_tensors=\"pt\", \n",
    "        max_length=max_input_length, \n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=max_length,\n",
    "            num_beams=num_beams,\n",
    "            early_stopping=True,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "    \n",
    "    translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translation\n",
    "\n",
    "# Test với câu mới (không có trong training data)\n",
    "test_sentences = [\n",
    "    \"Chào bạn\",\n",
    "    \"Tôi đói bụng\",\n",
    "    \"Bây giờ là mấy giờ?\",\n",
    "    \"Tôi cần giúp đỡ\",\n",
    "    \"Rất vui được gặp bạn\",\n",
    "    \"Hôm nay là thứ mấy?\",\n",
    "    \"Tôi không biết\",\n",
    "    \"Xin chào mọi người\"\n",
    "]\n",
    "\n",
    "print(\"🇻🇳 ➡️ 🇺🇸 TEST TRANSLATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, vn_text in enumerate(test_sentences, 1):\n",
    "    translation = translate_vietnamese(vn_text)\n",
    "    print(f\"{i}. 🇻🇳 {vn_text}\")\n",
    "    print(f\"   🇺🇸 {translation}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Interactive test - bạn có thể thay đổi câu này\n",
    "print(\"\\n🎮 TEST INTERACTIVE:\")\n",
    "print(\"Thay đổi câu dưới đây và chạy lại cell để test:\")\n",
    "\n",
    "your_sentence = \"Tôi yêu lập trình\"\n",
    "your_translation = translate_vietnamese(your_sentence)\n",
    "\n",
    "print(f\"\\n🇻🇳 Câu của bạn: {your_sentence}\")\n",
    "print(f\"🇺🇸 Bản dịch: {your_translation}\")\n",
    "\n",
    "# Tips cho người dùng\n",
    "print(\"\\n💡 TIPS:\")\n",
    "print(\"- Model nhỏ nên có thể chưa hoàn hảo\")\n",
    "print(\"- Câu càng đơn giản thì dịch càng tốt\")\n",
    "print(\"- Có thể training thêm để cải thiện\")\n",
    "print(\"- Thử với dataset lớn hơn để có kết quả tốt hơn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f953b628",
   "metadata": {},
   "source": [
    "## 🎉 Kết luận\n",
    "\n",
    "**Chúc mừng! Bạn đã hoàn thành việc fine-tune model dịch Việt-Anh!**\n",
    "\n",
    "### ✅ Những gì đã làm:\n",
    "1. **Cài đặt**: PyTorch 2.5.1+cu121 và thư viện cần thiết\n",
    "2. **Dataset**: Tạo 20 cặp câu Việt-Anh đơn giản\n",
    "3. **Model**: Load mT5-small và setup LoRA\n",
    "4. **Training**: Fine-tune với settings tối ưu\n",
    "5. **Test**: Kiểm tra chất lượng dịch thuật\n",
    "\n",
    "### 📈 Cách cải thiện:\n",
    "\n",
    "#### 1. **Dataset lớn hơn**\n",
    "```python\n",
    "# Sử dụng dataset từ Hugging Face\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"Helsinki-NLP/opus-100\", \"vi-en\")\n",
    "```\n",
    "\n",
    "#### 2. **Model lớn hơn**\n",
    "```python\n",
    "# Thử mT5-base thay vì mT5-small\n",
    "MODEL_NAME = \"google/mt5-base\"\n",
    "```\n",
    "\n",
    "#### 3. **Training lâu hơn**\n",
    "```python\n",
    "# Tăng epochs và giảm learning rate\n",
    "num_train_epochs=10\n",
    "learning_rate=3e-4\n",
    "```\n",
    "\n",
    "#### 4. **Hyperparameter tuning**\n",
    "```python\n",
    "# Thử các settings khác\n",
    "r=16, lora_alpha=32  # LoRA settings\n",
    "per_device_train_batch_size=4  # Batch size\n",
    "```\n",
    "\n",
    "### 🚀 Bước tiếp theo:\n",
    "\n",
    "1. **Sử dụng script có sẵn**:\n",
    "   ```bash\n",
    "   # Preprocess data\n",
    "   python -m src.data_processing.preprocess\n",
    "   \n",
    "   # Training\n",
    "   python -m src.training.fine_tune\n",
    "   \n",
    "   # Inference\n",
    "   python -m src.inference.translate --model_path \"path/to/model\" --text \"xin chào\"\n",
    "   ```\n",
    "\n",
    "2. **Chạy web interface**:\n",
    "   ```bash\n",
    "   python main.py\n",
    "   # Mở http://localhost:8000\n",
    "   ```\n",
    "\n",
    "3. **Deploy API**:\n",
    "   ```bash\n",
    "   uvicorn main:app --host 0.0.0.0 --port 8000\n",
    "   ```\n",
    "\n",
    "### 🎯 Kết quả mong đợi:\n",
    "- **Small dataset**: BLEU ~0.3-0.5\n",
    "- **Large dataset**: BLEU ~0.6-0.8\n",
    "- **Production ready**: BLEU >0.8\n",
    "\n",
    "### 📚 Tài liệu tham khảo:\n",
    "- [Hugging Face Transformers](https://huggingface.co/docs/transformers)\n",
    "- [PEFT Documentation](https://huggingface.co/docs/peft)\n",
    "- [mT5 Paper](https://arxiv.org/abs/2010.11934)\n",
    "\n",
    "### 🔧 Troubleshooting:\n",
    "- **Out of memory**: Giảm batch_size xuống 1\n",
    "- **Slow training**: Sử dụng GPU hoặc giảm model size\n",
    "- **Poor quality**: Tăng data hoặc training epochs\n",
    "\n",
    "**Happy coding! 🎉**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
